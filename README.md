# dbt_example
- PROJECT GOALS 

- Name: dbt_project_learning
- Deadline: 05/07/2024

Functional requirements:

* [X] Generate fake data (extract) (Python)
* [X] Create a database (load) (Python)
* [ ] Create a dbt project (transform) (By hand)
* [ ] Perform SQL queries on dbt (transform) (By hand, SQL)
* [ ] Analyse the data and produce a report (Tableau)
* [ ] Delete the data and database afterwards
* [X] Accessible on github

Optional features:

* [ ] Create ELT pipelines by connecting to airflow or another tool 
* [ ] Connect to a cloud-based database like Redshift, Azure, Snowflake etc
* [ ] Use social media or other data that is non-sensitive but unique
* [ ] Make it unique or special

Learning goals:
- 


Folder structure:
jaffle_shop_duck_db - folder for database + scripts + environment 
github = github stuff
.vscode = vscode stuff 
logs = dbt logs file that is auto generated 
models = part of database, make by hand, contains sql files, models 
staging = testing 
 
scripts = creating data and database and connecting it to dbt 
seeds = storage, csv files - not needed for cloud-based
target = output of your dbt functions, generated by your functions
venv = environment for running everything 
.devcontainer.json = ???

.sqlfluff
.sqlfluffgnore

.user.yml
dbt_project.yml = 
dbt-completion.bash

Dockerfile = ???

jaffleshop.duckdb

profiles.yml = 




